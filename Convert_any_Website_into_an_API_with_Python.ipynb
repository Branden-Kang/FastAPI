{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBsYyMJbDa4OgLI7rWrByv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://python.plainenglish.io/convert-any-website-into-an-api-with-python-508f11e9b4a7)"
      ],
      "metadata": {
        "id": "irVITxTEqtzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing the requirements"
      ],
      "metadata": {
        "id": "2sqhGEFlqwuz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ijvAzwPqq7G",
        "outputId": "56c0f437-1cb4-4e48-e365-55e00db86f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sanic\n",
            "  Downloading sanic-22.6.2-py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting httptools>=0.0.10\n",
            "  Downloading httptools-0.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (406 kB)\n",
            "\u001b[K     |████████████████████████████████| 406 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting sanic-routing<22.6.0,>=22.3.0\n",
            "  Downloading sanic_routing-22.3.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.7/dist-packages (from sanic) (5.4.0)\n",
            "Collecting aiofiles>=0.6.0\n",
            "  Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=5.0 in /usr/local/lib/python3.7/dist-packages (from sanic) (6.0.2)\n",
            "Collecting uvloop>=0.5.3\n",
            "  Downloading uvloop-0.16.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 63.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: websockets, uvloop, sanic-routing, httptools, aiofiles, sanic\n",
            "Successfully installed aiofiles-0.8.0 httptools-0.4.0 sanic-22.6.2 sanic-routing-22.3.0 uvloop-0.16.0 websockets-10.3\n"
          ]
        }
      ],
      "source": [
        "!pip install sanic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests-html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OePGAIVDqxOq",
        "outputId": "3e623ac1-78ab-4fb6-f613-28d7fdc49d95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html) (0.0.1)\n",
            "Collecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests-html) (2.23.0)\n",
            "Collecting w3lib\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (2022.6.15)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.12.0)\n",
            "Collecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (10.3)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.8.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html) (4.6.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html) (4.9.1)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (2.10)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (3.0.4)\n",
            "Building wheels for collected packages: fake-useragent, parse\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=d9f8f2cc258294ea132a3d4790fd478302392d4ddf166bf4b924267618968490\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=c16adcdc1bc3d4399b60df2f9349844048d47482e38addb53352224701bdf565\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n",
            "Successfully built fake-useragent parse\n",
            "Installing collected packages: urllib3, pyee, cssselect, w3lib, pyquery, pyppeteer, parse, fake-useragent, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-html-0.10.0 urllib3-1.25.11 w3lib-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. The Idea"
      ],
      "metadata": {
        "id": "OHdKVJ3Rqzc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests_html\n",
        "from sanic import Sanic, json\n",
        "from sanic.response import text\n",
        "\n",
        "app = Sanic(\"WebToAPI\")\n",
        "HOST = \"localhost\"\n",
        "PORT = 8000\n",
        "\n",
        "# Routes\n",
        "# We are going to add this later in the code\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=HOST, port=PORT, debug=True, auto_reload=True)"
      ],
      "metadata": {
        "id": "fc0aSwqRqye6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_heroes():\n",
        "    \"\"\"Returns the list of heroes from the Dota 2 Wiki\n",
        "    Returns:\n",
        "        json: A json containing the list of heroes\n",
        "    \"\"\"\n",
        "    # Load the page\n",
        "    sess = requests_html.HTMLSession()\n",
        "    url = 'https://dota2.fandom.com/wiki/Heroes'\n",
        "    res = sess.get(url)\n",
        "    # Retrieve the table\n",
        "    table = res.html.find('tbody', first=True)\n",
        "    table_urls = table.find('a')\n",
        "    table_urls = [x.absolute_links.pop() for x in table_urls]\n",
        "    # Clean data from strength, agility, intelligence\n",
        "    to_clean = ['Strength', 'Agility', 'Intelligence']\n",
        "    for i in to_clean:\n",
        "        table_urls = [x for x in table_urls if i not in x]\n",
        "    # Create the output\n",
        "    output = {\"heroes\": []}\n",
        "    for entry in table_urls:\n",
        "        output[\"heroes\"].append(\n",
        "            {\n",
        "               \"name\": entry.split('/')[-1]\n",
        "             , \"clean_name\": entry.split('/')[-1].replace('_',' ')\n",
        "             , \"url\": entry\n",
        "             }\n",
        "            )\n",
        "    return output"
      ],
      "metadata": {
        "id": "eENNDHn1q7AG"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}
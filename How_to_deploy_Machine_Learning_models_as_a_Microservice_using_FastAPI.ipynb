{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to deploy Machine Learning models as a Microservice using FastAPI.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcn+z6x0GmiMv8OG+yRpUT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIanfmHFkJRs"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/how-to-deploy-machine-learning-models-as-a-microservice-using-fastapi-b3a6002768af)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IEqQKZYkQTB"
      },
      "source": [
        "# Step 1. Make your model for which you want to create the API ready\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXXdSNZ2jSnd",
        "outputId": "fc11bb15-b726-42fc-e408-654545a28b37"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pickle\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
        "dataset = pd.read_csv(filepath_or_buffer=url,header=None,sep=',',names=names)\n",
        "\n",
        "# Split-out validation dataset\n",
        "array = dataset.values\n",
        "X = array[:,0:4]\n",
        "y = array[:,4]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# save the model to disk\n",
        "pickle.dump(classifier, open('LRClassifier.pkl', 'wb'))\n",
        "\n",
        "# load the model from disk\n",
        "loaded_model = pickle.load(open('LRClassifier.pkl', 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcLq7icXkZzj"
      },
      "source": [
        "# Step 2. Create API using FastAPI framework\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzH4k0uDk4Fp",
        "outputId": "cf9ead7a-9622-43d8-90a5-b820306fddf5"
      },
      "source": [
        "!pip install fastapi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.70.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 452 kB/s \n",
            "\u001b[?25hCollecting starlette==0.16.0\n",
            "  Downloading starlette-0.16.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 248 kB/s \n",
            "\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting anyio<4,>=3.0.0\n",
            "  Downloading anyio-3.3.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from starlette==0.16.0->fastapi) (3.7.4.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.16.0->fastapi) (2.10)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: sniffio, anyio, starlette, pydantic, fastapi\n",
            "Successfully installed anyio-3.3.4 fastapi-0.70.0 pydantic-1.8.2 sniffio-1.2.0 starlette-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVP-QKTPkYSZ"
      },
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "app = FastAPI()\n",
        "class IrisSpecies(BaseModel):\n",
        "    sepal_length: float\n",
        "    sepal_width: float\n",
        "    petal_length: float\n",
        "    petal_width: float\n",
        "\n",
        "@app.post('/predict')\n",
        "async def predict_species(iris: IrisSpecies):\n",
        "    data = iris.dict()\n",
        "    loaded_model = pickle.load(open('LRClassifier.pkl', 'rb'))\n",
        "    data_in = [[data['sepal_length'], data['sepal_width'], data['petal_length'], data['petal_width']]]\n",
        "    prediction = loaded_model.predict(data_in)\n",
        "    probability = loaded_model.predict_proba(data_in).max()\n",
        "    return {\n",
        "    'prediction': prediction[0],\n",
        "    'probability': probability\n",
        "    }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M750EjX1lDuL"
      },
      "source": [
        "import requests\n",
        "new_measurement = {\n",
        "\"sepal_length\": 1.2,\n",
        "\"sepal_width\": 2.3,\n",
        "\"petal_length\": 1.4,\n",
        "\"petal_width\": 2.8\n",
        "}\n",
        "response = requests.post('http://127.0.0.1:8000/predict', json=new_measurement)\n",
        "print(response.content)"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}